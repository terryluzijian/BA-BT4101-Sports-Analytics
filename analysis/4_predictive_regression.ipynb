{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictive Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Read data from the data folder\n",
    "race_df = pd.read_csv('data/race.csv', low_memory=False, index_col=0)\n",
    "horse_df = pd.read_csv('data/horse.csv', low_memory=False, index_col=0)\n",
    "individual_df = pd.read_csv('data/individual.csv', low_memory=False, index_col=0)\n",
    "trainer_df = pd.read_csv('data/trainer.csv', low_memory=False, index_col=0)\n",
    "jockey_df = pd.read_csv('data/jockey.csv', low_memory=False, index_col=0)\n",
    "horse_race_df = pd.read_csv('data/horse_race.csv', low_memory=False, index_col=0)\n",
    "horse_race_df['age_int'] = horse_race_df['sex_age'].apply(lambda x: re.search(r'\\d+', x).group(0)).astype(int)\n",
    "\n",
    "# Do some simple data transformation\n",
    "horse_race_df['run_date'] = horse_race_df['run_date'].apply(pd.Timestamp)\n",
    "horse_race_df = horse_race_df.sort_values(['horse_id', 'run_date'])\n",
    "try:\n",
    "    first_occur_df = pd.read_csv('data/first_occurence_race.csv', low_memory=False, index_col=0)\n",
    "    first_occur_df['run_date'] = first_occur_df['run_date'].apply(pd.Timestamp)\n",
    "except FileNotFoundError:\n",
    "    horse_race_sorted = horse_race_df.copy()\n",
    "    horse_id_set = set()\n",
    "    first_occur_dict = {}\n",
    "    for index, value in horse_race_sorted.iterrows():\n",
    "        if value['horse_id'] not in horse_id_set:\n",
    "            horse_id_set.add(value['horse_id'])\n",
    "            first_occur_dict[index] = value\n",
    "    first_occur_df = pd.DataFrame.from_dict(first_occur_dict, orient='index')\n",
    "    first_occur_df.to_csv('data/first_occurence_race.csv', encoding='utf-8')\n",
    "    \n",
    "columns_to_drop = [\n",
    "    'race', 'title', 'horse', 'sex_age',\n",
    "    'distance', 'run_time', 'breeder',\n",
    "    'jockey', 'margin', 'trainer_x', 'trainer_y', 'owner_x', 'owner_y', 'horse_name', 'date_of_birth', \n",
    "    'transaction_price', 'prize_obtained', 'race_record', 'highlight_race', 'relatives', 'status', 'prize'\n",
    "]\n",
    "for column in columns_to_drop:\n",
    "    try:\n",
    "        first_occur_df.drop(column, axis=1, inplace=True)\n",
    "        horse_race_df.drop(column, axis=1, inplace=True)\n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "horse_race_df = horse_race_df[horse_race_df['finishing_position'].apply(lambda x: bool(re.search(r'\\d+', x)))]\n",
    "horse_race_df['finishing_position'] = horse_race_df['finishing_position'].apply(lambda x: re.search(r'\\d+', x).group(0))\n",
    "horse_race_df['finishing_position'] = horse_race_df['finishing_position'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies_order_by_count(df, column_name):\n",
    "    # Get dummies by descending count order\n",
    "    return pd.get_dummies(df[column_name]).reindex(df[column_name].value_counts().index, axis=1).iloc[:, :-1]\n",
    "\n",
    "def parse_time_stamp(time_string):\n",
    "    # Parse timestamp expressed in hours\n",
    "    time_split = time_string.split(':')\n",
    "    hour = int(time_split[0])\n",
    "    if hour < 12:\n",
    "        return '10-12'\n",
    "    elif hour > 12 and hour < 15:\n",
    "        return '12-15'\n",
    "    else:\n",
    "        return '15-after'\n",
    "    \n",
    "def get_trainer_jockey_profile(df, individual):\n",
    "    # Merge with trainer/jockey dataframe\n",
    "    assert individual in ['trainer', 'jockey']\n",
    "    if individual == 'trainer':\n",
    "        merge_df = trainer_df\n",
    "    elif individual == 'jockey':\n",
    "        merge_df = jockey_df\n",
    "    df = df.merge(merge_df[['%s_id' % individual, 'date_of_birth', 'place_of_birth']], \n",
    "                  on='%s_id' % individual, suffixes=['', '_%s' % individual])\n",
    "    df['run_date'] = df['run_date'].apply(lambda x: pd.Timestamp(x))\n",
    "    df['date_of_birth'] = df['date_of_birth'].apply(lambda x: pd.Timestamp(x))\n",
    "    df['%s_age' % individual] = df['run_date'].subtract(df['date_of_birth']).dt.days / 365.0\n",
    "    df.drop(['date_of_birth'], axis=1, inplace=True)\n",
    "    df['place_of_birth_%s' % individual] = df['place_of_birth_%s' % individual].apply(lambda x: 'tokyo' if x == u'東京都' \\\n",
    "                                                                                      else 'outside_tokyo')\n",
    "    return df\n",
    "\n",
    "def feature_engineer(race_df, dummy=True, drop_columns=True):\n",
    "    \n",
    "    new_df = race_df.copy()\n",
    "\n",
    "    # Feature engineering\n",
    "    has_horse_weight = new_df['horse_weight'].apply(lambda x: bool(re.search(r'(\\d+)\\(.+\\)', x)))\n",
    "    new_df = new_df[has_horse_weight]\n",
    "    new_df['horse_weight_increase'] = new_df['horse_weight'].apply(lambda x: re.search(r'\\(.?(\\d+)\\)', x).group(1))\n",
    "    new_df['horse_weight_increase'] = new_df['horse_weight_increase'].astype(float)\n",
    "    new_df['horse_weight'] = new_df['horse_weight'].apply(lambda x: re.search(r'(\\d+)\\(.+\\)', x).group(1))\n",
    "    new_df['horse_weight'] = new_df['horse_weight'].astype(float)\n",
    "\n",
    "    new_df['time'] = new_df['time'].apply(lambda x: parse_time_stamp(x))\n",
    "\n",
    "    for individual in ['jockey', 'trainer']:\n",
    "        new_df = get_trainer_jockey_profile(new_df, individual)\n",
    "\n",
    "    # Get dummy columns\n",
    "    if dummy:\n",
    "        dummied_cols = ['place', 'type', 'track', 'weather', 'condition', 'gender', 'breed', 'bracket', 'horse_number', \n",
    "                        'time', 'place_of_birth_jockey', 'place_of_birth_trainer']\n",
    "        for cols in dummied_cols:\n",
    "            new_df = new_df.join(get_dummies_order_by_count(new_df, \n",
    "                                                           cols).rename(columns=lambda x: '-'.join([cols, str(x)])))\n",
    "            try:\n",
    "                new_df.drop(cols, axis=1, inplace=True)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Drop some other columns\n",
    "    columns_to_drop_again = ['finishing_position', 'corner_position', 'run_time_last_600', \n",
    "                             'jockey_id', 'owner_id', 'trainer_id', 'breeder_id', \n",
    "                             'parents', 'age_int', 'place_of_birth']\n",
    "    if drop_columns:\n",
    "        for cols in columns_to_drop_again:\n",
    "            try:\n",
    "                new_df.drop(cols, axis=1, inplace=True)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    return new_df.sort_values(['horse_id', 'run_date']).set_index(['horse_id', 'run_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 OLS for First Occurence Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_df_first = feature_engineer(first_occur_df)\n",
    "X_first = new_df_first.loc[:, new_df_first.columns != 'run_time_1000']\n",
    "y_first = new_df_first.loc[:, 'run_time_1000']\n",
    "X_first = sm.add_constant(X_first)\n",
    "results = sm.OLS(y_first, X_first).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 OLS for Full Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_df_full = feature_engineer(horse_race_df)\n",
    "X_full = new_df_full.loc[:, new_df_full.columns != 'run_time_1000']\n",
    "y_full = new_df_full.loc[:, 'run_time_1000']\n",
    "X_full = sm.add_constant(X_full)\n",
    "results = sm.OLS(y_full, X_full).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "horse_race_df_grp_by = horse_race_df.set_index(['horse_id', 'run_date'])\n",
    "horse_race_df_grp_by['run_time_diff'] = horse_race_df_grp_by['run_time_1000'].diff()\n",
    "horse_race_df_grp_by = horse_race_df_grp_by[~horse_race_df_grp_by.index.isin(first_occur_df.set_index(['horse_id', \n",
    "                                                                                                       'run_date']).index)]\n",
    "horse_race_df_grp_by.reset_index(inplace=True)\n",
    "new_df_full_diff = feature_engineer(horse_race_df_grp_by)\n",
    "new_df_full_diff['last_run_time'] = new_df_full_diff['run_time_1000'] - new_df_full_diff['run_time_diff']\n",
    "new_df_full_diff.drop('run_time_diff', inplace=True, axis=1)\n",
    "\n",
    "X_full_diff = new_df_full_diff.loc[:, new_df_full_diff.columns != 'run_time_1000']\n",
    "y_full_diff = new_df_full_diff.loc[:, 'run_time_1000']\n",
    "X_full_diff = sm.add_constant(X_full_diff)\n",
    "results_diff = sm.OLS(y_full_diff, X_full_diff).fit()\n",
    "results_diff.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_window = 3\n",
    "try:\n",
    "    df_combined = pd.read_csv('data/horse_race_combined.csv', low_memory=False, index_col=0)\n",
    "    df_combined['run_date'] = df_combined['run_date'].apply(lambda x: pd.Timestamp(x))\n",
    "    df_combined = df_combined.sort_values(['horse_id', 'run_date'])\n",
    "    \n",
    "    df_combined = df_combined.iloc[:5000]\n",
    "    \n",
    "    df_combined.set_index(['horse_id', 'run_date'], inplace=True)\n",
    "    df_combined = df_combined[~df_combined.index.isin(first_occur_df.sort_values(['horse_id', 'run_date']).set_index(['horse_id', 'run_date']).index)]\n",
    "except FileNotFoundError:\n",
    "    df_combined = horse_race_df.set_index(['horse_id', 'run_date'])\n",
    "    df_combined['run_time_diff'] = df_combined['run_time_1000'].diff()\n",
    "    df_combined['last_run_time'] = df_combined['run_time_1000'] - df_combined['run_time_diff']\n",
    "    df_combined['run_time_quo'] = df_combined['run_time_1000'] / df_combined['last_run_time']\n",
    "    df_combined['run_time_mean'] = df_combined['last_run_time']\n",
    "\n",
    "    df_reset = df_combined['run_time_mean'].reset_index()\n",
    "    horse_id_lst = list(df_reset['horse_id'])\n",
    "    run_time_mean_lst = list(df_reset['run_time_mean'])\n",
    "    new_run_time_mean_lst = []\n",
    "    new_run_time_median_lst = []\n",
    "    curr_index = horse_id_lst[0]\n",
    "    curr_count = 0\n",
    "    curr_sum = 0\n",
    "    curr_stored = []\n",
    "    for index, value in zip(horse_id_lst, run_time_mean_lst):\n",
    "        if index != curr_index:\n",
    "            curr_count = 1\n",
    "            curr_sum = value\n",
    "            curr_index = index\n",
    "            curr_stored = [value]\n",
    "        else:\n",
    "            curr_count += 1\n",
    "            curr_sum += value\n",
    "            curr_stored.append(value)\n",
    "        new_run_time_mean_lst.append(curr_sum / (curr_count * 1.0))\n",
    "        new_run_time_median_lst.append(np.median(curr_stored))\n",
    "    df_combined['run_time_mean'] = pd.Series(new_run_time_mean_lst, index=df_combined.index)\n",
    "    df_combined['run_time_median'] = pd.Series(new_run_time_median_lst, index=df_combined.index)\n",
    "\n",
    "    for window in range(2, max_window + 1):\n",
    "        ma = df_combined.groupby(level=0)['run_time_1000'].rolling(window).mean().groupby(level=0).shift(1)\n",
    "        ma = ma.reset_index(level=1)['run_time_1000'].reset_index()\n",
    "        ewma = df_combined.groupby(level=0)['run_time_1000'].apply(lambda series: series.ewm(ignore_na=True, \n",
    "                                                                                             min_periods=window, \n",
    "                                                                                             adjust=True,\n",
    "                                                                                             com=0.030927835051546).mean())\n",
    "        ewma = ewma.groupby(level=0).shift(1)\n",
    "        df_combined['run_time_ma_window_%s' % str(window)] = ma.set_index(['horse_id', 'run_date'])['run_time_1000']\n",
    "        df_combined['run_time_ewma_window_%s' % str(window)] = ewma\n",
    "    df_combined.reset_index().to_csv('data/horse_race_combined.csv', encoding='utf-8')\n",
    "\n",
    "dependent = ['run_time_1000',\n",
    "             'run_time_diff', 'run_time_quo', \n",
    "             'run_time_mean', 'run_time_median'] + \\\n",
    "            ['run_time_ma_window_%s' % str(idx) for idx in range(2, max_window + 1)] + \\\n",
    "            ['run_time_ewma_window_%s' % str(idx) for idx in range(2, max_window + 1)]\n",
    "df_combined_y = df_combined[dependent].copy()\n",
    "df_combined_x = df_combined[list(filter(lambda x: x not in dependent, df_combined.columns))].copy()\n",
    "df_y_original_dict = {}\n",
    "df_y_original_dict['run_time_diff'] = df_combined_x['last_run_time']\n",
    "df_y_original_dict['run_time_quo'] = df_combined_x['last_run_time']\n",
    "for col_name in dependent[3:]:\n",
    "    df_combined_y[col_name + '_diff'] = df_combined_y['run_time_1000'] - df_combined_y[col_name]\n",
    "    df_combined_y[col_name + '_quo'] = df_combined_y['run_time_1000'] / df_combined_y[col_name]\n",
    "    df_y_original_dict[col_name + '_diff'] = df_combined_y[col_name]\n",
    "    df_y_original_dict[col_name + '_quo'] = df_combined_y[col_name]\n",
    "    df_combined_y.drop(col_name, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_y[list(filter(lambda x: 'diff' in x or 'quo' in x, df_combined_y.columns))].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model testing for run time residual\n",
    "x = feature_engineer(df_combined_x.reset_index())\n",
    "x = x.drop('last_run_time', axis=1)\n",
    "y = df_combined_y.loc[df_combined_y.index.isin(x.index), 'run_time_diff']\n",
    "\n",
    "# OLS\n",
    "reg = linear_model.LinearRegression(fit_intercept=False)\n",
    "scores_reg = cross_val_score(reg, x, y, scoring='neg_mean_squared_error')\n",
    "print(\"RMSE for OLS: %0.5f\" % np.sqrt(-scores_reg.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelComparer(object): \n",
    "    \n",
    "    no_drop_col = ['run_time_1000']\n",
    "    \n",
    "    def __init__(self, X_df, y_df, original_y_df_dict):\n",
    "        self.X = feature_engineer(X_df.reset_index())\n",
    "        self.y = y_df[y_df.index.isin(self.X.index)]\n",
    "        self.y_original = original_y_df_dict\n",
    "        self.run_time_serie = self.y['run_time_1000']\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.3)\n",
    "        self.model_dict = {}\n",
    "        \n",
    "    def add_model(self, model_method, model_name):\n",
    "        \n",
    "        print('Adding model named %s ' % model_name)\n",
    "        self.model_dict[model_name] = {}\n",
    "        \n",
    "        for y_col_name in self.y.columns:\n",
    "            X_train = self.X_train.copy()\n",
    "            X_test = self.X_test.copy()                \n",
    "            model = model_method\n",
    "            self.model_dict[model_name]['Model Spec'] = repr(model)\n",
    "            \n",
    "            if y_col_name not in self.no_drop_col:\n",
    "                X_train.drop('last_run_time', axis=1, inplace=True)\n",
    "                X_test.drop('last_run_time', axis=1, inplace=True)\n",
    "                \n",
    "            y_train = self.y_train[y_col_name].dropna()\n",
    "            y_test = self.y_test[y_col_name].dropna()\n",
    "            \n",
    "            X_train = X_train[X_train.index.isin(y_train.index)]\n",
    "            X_test = X_test[X_test.index.isin(y_test.index)]\n",
    "                     \n",
    "            if 'normalized' in model_name.lower():\n",
    "                scaler = StandardScaler()\n",
    "                scaler.fit(X_train)\n",
    "                X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index)\n",
    "                X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index)\n",
    "            \n",
    "            print('Performing analysis on column %s for model %s (Size: %s)' % (y_col_name, model_name, str(X_train.shape)))\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            if y_col_name not in self.no_drop_col:\n",
    "                y_pred = pd.Series(y_pred, index=X_test.index)\n",
    "                original_serie = df_y_original_dict[y_col_name]\n",
    "                original_serie = original_serie[original_serie.index.isin(y_pred.index)]\n",
    "                run_time_serie = self.run_time_serie[self.run_time_serie.index.isin(y_pred.index)]\n",
    "                if 'quo' in y_col_name:\n",
    "                    y_pred = y_pred * original_serie\n",
    "                elif 'diff' in y_col_name:\n",
    "                    y_pred = y_pred + original_serie\n",
    "                self.model_dict[model_name]['Transformed RMSE: %s (%s)' % (y_col_name, \n",
    "                                                                           X_train.shape[0])] = '%.6f' % self.get_rmse(y_pred, \n",
    "                                                                                                                       run_time_serie)  \n",
    "            else:\n",
    "                self.model_dict[model_name]['Original RMSE: %s (%s)' % (y_col_name, \n",
    "                                                                        X_train.shape[0])] = '%.6f' % self.get_rmse(y_pred, \n",
    "                                                                                                                    y_test)\n",
    "        \n",
    "    def get_report(self):\n",
    "        try:\n",
    "            df = pd.DataFrame.from_dict(self.model_dict)\n",
    "            return df.sort_values(df.columns[0])\n",
    "        except IndexError:\n",
    "            return\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_rmse(y_true, y_pred):\n",
    "        diff = np.sum((y_true - y_pred) ** 2)\n",
    "        return (diff / y_true.shape[0]) ** 1/2\n",
    "    \n",
    "mc = ModelComparer(df_combined_x, df_combined_y, df_y_original_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_ols(**kwargs):\n",
    "    reg = linear_model.LinearRegression(**kwargs)\n",
    "    return reg\n",
    "\n",
    "def get_xgboost(**kwargs):\n",
    "    xgb_model = xgb.XGBRegressor(**kwargs)\n",
    "    return xgb_model\n",
    "\n",
    "def get_decision_tree(**kwargs):\n",
    "    dt = DecisionTreeRegressor(**kwargs)\n",
    "    return dt\n",
    "\n",
    "def get_random_forest(**kwargs):\n",
    "    regr = RandomForestRegressor(**kwargs)\n",
    "    return regr\n",
    "\n",
    "def get_gbm(**kwargs):\n",
    "    clf = GradientBoostingRegressor(**kwargs)\n",
    "    return clf\n",
    "\n",
    "def get_ann(**kwargs):\n",
    "    mlp = MLPRegressor(**kwargs)\n",
    "    return mlp\n",
    "\n",
    "# Add base model\n",
    "mc.add_model(get_ols(fit_intercept=False), 'OLS - Base Model')\n",
    "mc.add_model(get_xgboost(learning_rate=0.1), 'XGB - Base Model (0.1LR)')\n",
    "mc.add_model(get_decision_tree(max_depth=6), 'DT - Base Model (6MD)')\n",
    "mc.add_model(get_random_forest(max_depth=6), 'RF - Base Model (6MD)')\n",
    "mc.add_model(get_gbm(n_estimators=500, max_depth=6, min_samples_split=2, learning_rate=0.1, loss='ls'), 'GBM - Base Model (6MD, 0.1LR)')\n",
    "mc.add_model(get_ann(max_iter=100000), 'ANN - Base Model (normalized, 100000MI)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some specs for plotting\n",
    "mpl.rcParams['figure.figsize'] = (16.0, 8.0)\n",
    "mpl.style.use('ggplot')\n",
    "\n",
    "value_df = mc.get_report().dropna().iloc[:-1, :]\n",
    "value_df = value_df.applymap(lambda x: float(x))\n",
    "sns.heatmap(value_df, annot=True, fmt='g', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
