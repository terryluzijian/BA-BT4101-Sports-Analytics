{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable R cell for later use\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cmocean\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from feature_engineering import feature_engineer, drop_cols\n",
    "from grid_search import get_best_model\n",
    "from mlxtend.regressor import StackingRegressor, StackingCVRegressor\n",
    "from model_comparer import ModelComparer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the data folder\n",
    "file_directory = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), '')) + '\\\\'\n",
    "sample = False\n",
    "sample_size = 10000\n",
    "        \n",
    "max_window = 3\n",
    "\n",
    "try:\n",
    "    df_combined = pd.read_csv(file_directory + 'data/horse_race_combined.csv', low_memory=False, index_col=0)\n",
    "    df_combined['run_date'] = df_combined['run_date'].apply(lambda x: pd.Timestamp(x))\n",
    "    df_combined = df_combined.sort_values(['horse_id', 'run_date'])\n",
    "    \n",
    "    if sample:\n",
    "        df_combined = df_combined.sort_values('run_date').iloc[:sample_size]\n",
    "    \n",
    "    df_combined.set_index(['horse_id', 'run_date'], inplace=True)\n",
    "    \n",
    "    first_occur_df = pd.read_csv(file_directory + 'data/first_occurence_race.csv', low_memory=False, index_col=0)\n",
    "    first_occur_df['run_date'] = first_occur_df['run_date'].apply(pd.Timestamp)\n",
    "    first_occur_df = first_occur_df.sort_values(['horse_id', 'run_date'])\n",
    "    drop_cols(first_occur_df)\n",
    "    \n",
    "    df_combined = df_combined[~df_combined.index.isin(first_occur_df.sort_values(['horse_id', 'run_date']).set_index(['horse_id', 'run_date']).index)]\n",
    "except FileNotFoundError:\n",
    "    horse_race_df = pd.read_csv(file_directory + 'data/horse_race.csv', low_memory=False, index_col=0)\n",
    "    horse_race_df['age_int'] = horse_race_df['sex_age'].apply(lambda x: re.search(r'\\d+', x).group(0)).astype(int)\n",
    "    horse_race_df['run_date'] = horse_race_df['run_date'].apply(pd.Timestamp)\n",
    "    horse_race_df = horse_race_df.sort_values(['horse_id', 'run_date'])\n",
    "    drop_cols(horse_race_df)\n",
    "    \n",
    "    df_combined = horse_race_df.set_index(['horse_id', 'run_date'])\n",
    "    df_combined['run_time_diff'] = df_combined['run_time_1000'].diff()\n",
    "    df_combined['last_run_time'] = df_combined['run_time_1000'] - df_combined['run_time_diff']\n",
    "    df_combined['run_time_quo'] = df_combined['run_time_1000'] / df_combined['last_run_time']\n",
    "    df_combined['run_time_mean'] = df_combined['last_run_time']\n",
    "\n",
    "    df_reset = df_combined['run_time_mean'].reset_index()\n",
    "    horse_id_lst = list(df_reset['horse_id'])\n",
    "    run_time_mean_lst = list(df_reset['run_time_mean'])\n",
    "    new_run_time_mean_lst = []\n",
    "    new_run_time_median_lst = []\n",
    "    curr_index = horse_id_lst[0]\n",
    "    curr_count = 0\n",
    "    curr_sum = 0\n",
    "    curr_stored = []\n",
    "    for index, value in zip(horse_id_lst, run_time_mean_lst):\n",
    "        if index != curr_index:\n",
    "            curr_count = 1\n",
    "            curr_sum = value\n",
    "            curr_index = index\n",
    "            curr_stored = [value]\n",
    "        else:\n",
    "            curr_count += 1\n",
    "            curr_sum += value\n",
    "            curr_stored.append(value)\n",
    "        new_run_time_mean_lst.append(curr_sum / (curr_count * 1.0))\n",
    "        new_run_time_median_lst.append(np.median(curr_stored))\n",
    "    df_combined['run_time_mean'] = pd.Series(new_run_time_mean_lst, index=df_combined.index)\n",
    "    df_combined['run_time_median'] = pd.Series(new_run_time_median_lst, index=df_combined.index)\n",
    "\n",
    "    for window in range(2, max_window + 1):\n",
    "        ma = df_combined.groupby(level=0)['run_time_1000'].rolling(window).mean().groupby(level=0).shift(1)\n",
    "        ma = ma.reset_index(level=1)['run_time_1000'].reset_index()\n",
    "        ewma = df_combined.groupby(level=0)['run_time_1000'].apply(lambda series: series.ewm(ignore_na=True, \n",
    "                                                                                             min_periods=window, \n",
    "                                                                                             adjust=True,\n",
    "                                                                                             com=0.030927835051546).mean())\n",
    "        ewma = ewma.groupby(level=0).shift(1)\n",
    "        df_combined['run_time_ma_window_%s' % str(window)] = ma.set_index(['horse_id', 'run_date'])['run_time_1000']\n",
    "        df_combined['run_time_ewma_window_%s' % str(window)] = ewma\n",
    "    df_combined.reset_index().to_csv('data/horse_race_combined.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent = ['run_time_1000',\n",
    "             'run_time_diff', 'run_time_quo', \n",
    "             'run_time_mean', 'run_time_median'] + \\\n",
    "            ['run_time_ma_window_%s' % str(idx) for idx in range(2, max_window + 1)] + \\\n",
    "            ['run_time_ewma_window_%s' % str(idx) for idx in range(2, max_window + 1)]\n",
    "df_combined_y = df_combined[dependent].copy()\n",
    "df_combined_x = df_combined[list(filter(lambda x: x not in dependent, df_combined.columns))].copy()\n",
    "df_y_original_dict = {}\n",
    "df_y_original_dict['run_time_diff'] = df_combined_x['last_run_time']\n",
    "df_y_original_dict['run_time_quo'] = df_combined_x['last_run_time']\n",
    "for col_name in dependent[3:]:\n",
    "    df_combined_y[col_name + '_diff'] = df_combined_y['run_time_1000'] - df_combined_y[col_name]\n",
    "    df_combined_y[col_name + '_quo'] = df_combined_y['run_time_1000'] / df_combined_y[col_name]\n",
    "    df_y_original_dict[col_name + '_diff'] = df_combined_y[col_name]\n",
    "    df_y_original_dict[col_name + '_quo'] = df_combined_y[col_name]\n",
    "    df_combined_y.drop(col_name, axis=1, inplace=True)\n",
    "df_combined_y[list(filter(lambda x: 'diff' in x or 'quo' in x, df_combined_y.columns))].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 OLS Trial Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model testing for run time residual\n",
    "x = feature_engineer(df_combined_x.reset_index(), 'df_combined_all' if not sample else 'df_sampled')\n",
    "y = df_combined_y.loc[df_combined_y.index.isin(x.index), 'run_time_diff']\n",
    "\n",
    "# OLS\n",
    "reg = LinearRegression(fit_intercept=True)\n",
    "scores_reg = cross_val_score(reg, x, y, scoring='neg_mean_squared_error')\n",
    "print(\"RMSE for OLS: %0.5f\" % np.sqrt(-scores_reg.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Baseline Regression Models and Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    report_directory = file_directory + 'predictive/report/'\n",
    "    \n",
    "    # Initiate class object\n",
    "    mc = ModelComparer(df_combined_x, df_combined_y, df_y_original_dict, sampled=sample, random_state=37, ratio=0.8)\n",
    "    r_square_score = make_scorer(ModelComparer.get_r_squared, greater_is_better=True)\n",
    "    rmse_score = make_scorer(ModelComparer.get_rmse, greater_is_better=False)\n",
    "    \n",
    "    rmse_report = pd.read_csv(report_directory + 'rmse_report_baseline.csv', index_col=0)\n",
    "    rsquare_report = pd.read_csv(report_directory + 'rsquare_report_baseline.csv', index_col=0)\n",
    "    meta_report = pd.read_csv(report_directory + 'meta_report_baseline.csv', index_col=0)\n",
    "except FileNotFoundError:\n",
    "    # Add base model\n",
    "    mc.add_model(LinearRegression, model_name='OLS - Base Model', fit_intercept=True)\n",
    "    mc.add_model(XGBRegressor, 'XGB - Base Model (0.1LR)', learning_rate=0.1)\n",
    "    mc.add_model(DecisionTreeRegressor, 'DT - Base Model (6MD)', max_depth=6)\n",
    "    mc.add_model(RandomForestRegressor, 'RF - Base Model (6MD, 20E)', max_depth=6, n_estimators=20)\n",
    "    mc.add_model(GradientBoostingRegressor, 'GBM - Base Model (6MD, 0.1LR)', \n",
    "                 n_estimators=100, max_depth=6, min_samples_split=2, learning_rate=0.1)\n",
    "\n",
    "    # Add ANN with verbose as True\n",
    "    mc.add_model(MLPRegressor, 'ANN - Base Model (normalized, 100000MI, 0.01LR, 300HL)',\n",
    "                 max_iter=100000, learning_rate_init=0.01, hidden_layer_sizes=(300,), activation='tanh', \n",
    "                 verbose=True)\n",
    "\n",
    "    # Stacking model\n",
    "    ols_base = LinearRegression(fit_intercept=True)\n",
    "    xgb_base = XGBRegressor(learning_rate=0.1)\n",
    "    dt_base = DecisionTreeRegressor(max_depth=6)\n",
    "    rf_base = RandomForestRegressor(max_depth=6, n_estimators=20)\n",
    "    gbm_base = GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_split=2, learning_rate=0.1)\n",
    "    ann_base = MLPRegressor(max_iter=100000, learning_rate_init=0.01, hidden_layer_sizes=(300,), activation='tanh',  \n",
    "                            verbose=False)\n",
    "    xgb_meta = XGBRegressor(learning_rate=0.1)\n",
    "    mc.add_model(StackingRegressor, 'Meta - XGB (0.1LR)',\n",
    "                 regressors=[ols_base, xgb_base, dt_base, rf_base, gbm_base, ann_base], \n",
    "                 meta_regressor=xgb_meta)\n",
    "\n",
    "    # Get model report\n",
    "    rmse_report = mc.get_report(filter_word='RMSE')\n",
    "    rsquare_report = mc.get_report(filter_word='R^2')\n",
    "    rmse_report.to_csv(file_directory + 'predictive/report/rmse_report_baseline.csv')\n",
    "    rsquare_report.to_csv(file_directory + 'predictive/report/rsquare_report_baseline.csv')\n",
    "    \n",
    "    meta_report = mc.get_meta_report()\n",
    "    meta_report.to_csv(file_directory + 'predictive/report/meta_report_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some specs for plotting\n",
    "mpl.rcParams['figure.figsize'] = (16.0, 8.0)\n",
    "mpl.style.use('ggplot')\n",
    "sns.heatmap(meta_report.reset_index().set_index(['model_name', 'index']).astype(float), annot=True, fmt='.2f', cmap='RdYlBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_df = rmse_report.dropna().astype(float).iloc[:, :]\n",
    "value_df = value_df.applymap(lambda x: float(x))\n",
    "sns.heatmap(value_df, annot=True, fmt='g', cmap='RdYlBu_r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_df = rmse_report.dropna().astype(float).iloc[:, 1:]\n",
    "value_df = value_df.applymap(lambda x: float(x))\n",
    "sns.heatmap(value_df, annot=True, fmt='g', cmap='RdYlBu_r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_df = rsquare_report.dropna().astype(float).iloc[:, :]\n",
    "value_df = value_df.applymap(lambda x: float(x))\n",
    "sns.heatmap(value_df, annot=True, fmt='g', cmap='RdYlBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Artificial Nerural Network Hyper-parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ann_tuned_params = {\n",
    "    'activation': ['relu', 'tanh'], \n",
    "    'learning_rate_init': [0.01, 0.001, 0.002], \n",
    "    'max_iter': [100000, ], \n",
    "    'hidden_layer_sizes': [(100, ), (150, ), (200, ), (250, ), (300, ), (350, )]\n",
    "}\n",
    "get_best_model(mc, 'ann', MLPRegressor, ann_tuned_params, n_jobs=1, randomized=False,\n",
    "               scoring=rmse_score, verbose=2,\n",
    "               filter_func=lambda x: 'run_time_1000' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Random Forest Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_tuned_params = {\n",
    "    'n_estimators': np.arange(20, 70, 10), \n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': np.arange(5, 10, 1)\n",
    "}\n",
    "\n",
    "get_best_model(mc, 'rf', RandomForestRegressor, rf_tuned_params, n_jobs=-1, randomized=True,\n",
    "               scoring=rmse_score, verbose=2, \n",
    "               filter_func=lambda x: 'run_time_1000' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 XGBoost Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned_params = {\n",
    "    'max_depth': np.arange(3, 11, 2),\n",
    "    'subsample': np.arange(0.6, 1.1, 0.1),\n",
    "    'colsample_bytree': np.arange(0.6, 1.2, 0.2),\n",
    "    'min_child_weight': np.arange(1, 11, 3),\n",
    "    'gamma': np.arange(0, 0.5, 1),\n",
    "    'reg_alpha': [0, 0.001, 0.01]\n",
    "} \n",
    "get_best_model(mc, 'xgb', XGBRegressor, xgb_tuned_params, n_jobs=-1, randomized=True,\n",
    "               scoring=rmse_score, verbose=2, \n",
    "               filter_func=lambda x: 'run_time_1000' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 Gradient Boost Machine Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_tuned_params = {\n",
    "    'n_estimators': np.arange(100, 220, 20),\n",
    "    'max_depth': np.arange(5, 12, 2),\n",
    "    'min_samples_split': np.arange(100, 1000, 200),\n",
    "    'min_samples_leaf': np.arange(30, 90, 20),\n",
    "    'max_features': np.arange(20, 50, 10),\n",
    "    'subsample': np.arange(0.6, 1, 0.1)\n",
    "}\n",
    "get_best_model(mc, 'gbm', GradientBoostingRegressor, gbm_tuned_params, n_jobs=-1, randomized=True,\n",
    "               scoring=rmse_score, verbose=2, \n",
    "               filter_func=lambda x: 'run_time_1000' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 OLS Stacking Model with Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking model trial code (disable the comment to start)\n",
    "if 1 == 0:\n",
    "    ols = LinearRegression(fit_intercept=False)\n",
    "    xgb = XGBRegressor(learning_rate=0.1)\n",
    "    dt = DecisionTreeRegressor()\n",
    "    rf = RandomForestRegressor()\n",
    "    ann = MLPRegressor(max_iter=100000, learning_rate_init=0.01, activation='tanh')\n",
    "    gbm = GradientBoostingRegressor(learning_rate=0.1)\n",
    "\n",
    "    stack_tuned_params = {'xgbregressor__max_depth': [6, 9],\n",
    "                          'xgbregressor__min_child_weight': [3, 10],\n",
    "                          'xgbregressor__subsample': [0.8, 1],        \n",
    "                          'randomforestregressor__n_estimators': [20, 40], \n",
    "                          'randomforestregressor__max_depth': [5, 6],\n",
    "                          'mlpregressor__hidden_layer_sizes': [(100, ), (200, ), (250, ), (350, )],\n",
    "                          'gradientboostingregressor__n_estimators': [20, 50, 100],\n",
    "                          'gradientboostingregressor__max_features': [20, 30, 'auto'],\n",
    "                          'gradientboostingregressor__subsample': [0.8, 1]}\n",
    "    ols_meta = LinearRegression(fit_intercept=True)\n",
    "    get_best_model(mc, 'ols_stack', \n",
    "                   model_method=StackingCVRegressor, \n",
    "                   tuned_params=stack_tuned_params, \n",
    "                   scoring=rmse_score, verbose=1,\n",
    "                   regressors=[ols, xgb, dt, rf, ann, gbm], \n",
    "                   meta_regressor=ols_meta, \n",
    "                   use_features_in_secondary=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
